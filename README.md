# Procesamiento de Datos en Databricks ğŸš€

Este repositorio contiene scripts y notebooks para procesar grandes volÃºmenes de datos en Databricks utilizando PySpark.

## ğŸ“‚ Estructura del Proyecto
- `data/` â†’ Datos de entrada en formatos CSV, JSON y Parquet.
- `notebooks/` â†’ Notebooks de Databricks con cÃ³digo y anÃ¡lisis.
- `scripts/` â†’ Scripts en PySpark para limpieza y transformaciÃ³n de datos.

## ğŸ›  InstalaciÃ³n y ConfiguraciÃ³n
### Requisitos
- Python 3.8+
- PySpark
- Databricks CLI (opcional)

### InstalaciÃ³n
```bash
git clone https://github.com/usuario/databricks-data-processing.git
cd databricks-data-processing
pip install -r requirements.txt
