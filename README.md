# Procesamiento de Datos en Databricks 

Este repositorio contiene scripts y notebooks para procesar grandes volúmenes de datos en Databricks utilizando PySpark.

## Estructura del Proyecto
- `data/` → Datos de entrada en formatos CSV, JSON y Parquet.
- `notebooks/` → Notebooks de Databricks con código y análisis.
- `scripts/` → Scripts en PySpark para limpieza y transformación de datos.

## Instalación y Configuración
### Requisitos
- Python 3.8+
- PySpark
- Databricks CLI (opcional)

### Instalación
```bash
git clone https://github.com/usuario/databricks-data-processing.git
cd databricks-data-processing
pip install -r requirements.txt
