# Procesamiento de Datos en Databricks 

Este repositorio contiene scripts y notebooks para procesar grandes vol√∫menes de datos en Databricks utilizando PySpark.

## Estructura del Proyecto
- `data/` ‚Üí Datos de entrada en formatos CSV, JSON y Parquet.
- `notebooks/` ‚Üí Notebooks de Databricks con c√≥digo y an√°lisis.
- `scripts/` ‚Üí Scripts en PySpark para limpieza y transformaci√≥n de datos.

## üõ† Instalaci√≥n y Configuraci√≥n
### Requisitos
- Python 3.8+
- PySpark
- Databricks CLI (opcional)

### Instalaci√≥n
```bash
git clone https://github.com/usuario/databricks-data-processing.git
cd databricks-data-processing
pip install -r requirements.txt
